[
  {
    "id": "2503.03987v1",
    "title": "RetinalGPT: A Retinal Clinical Preference Conversational Assistant\n  Powered by Large Vision-Language Models",
    "date": "2025-03-06",
    "attention_score": 3.87,
    "attention_components": {
      "base_score": 2.0,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04839v1",
    "title": "Advancing Multimodal In-Context Learning in Large Vision-Language Models\n  with Task-aware Demonstrations",
    "date": "2025-03-05",
    "attention_score": 3.84,
    "attention_components": {
      "base_score": 2.0,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04543v1",
    "title": "Keeping Yourself is Important in Downstream Tuning Multimodal Large\n  Language Model",
    "date": "2025-03-06",
    "attention_score": 3.48,
    "attention_components": {
      "base_score": 1.8,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04229v1",
    "title": "Synthetic Data is an Elegant GIFT for Continual Vision-Language Models",
    "date": "2025-03-06",
    "attention_score": 3.48,
    "attention_components": {
      "base_score": 1.8,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03651v1",
    "title": "DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in\n  Multimodal Cycles",
    "date": "2025-03-05",
    "attention_score": 3.45,
    "attention_components": {
      "base_score": 1.8,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05543v1",
    "title": "Pi-GPS: Enhancing Geometry Problem Solving by Unleashing the Power of\n  Diagrammatic Information",
    "date": "2025-03-07",
    "attention_score": 3.12,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05093v1",
    "title": "Visual Cues of Gender and Race are Associated with Stereotyping in\n  Vision-Language Models",
    "date": "2025-03-07",
    "attention_score": 3.12,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05204v1",
    "title": "Data-Efficient Generalization for Zero-shot Composed Image Retrieval",
    "date": "2025-03-07",
    "attention_score": 3.12,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05383v1",
    "title": "VLMs Play StarCraft II: A Benchmark and Multimodal Decision Method",
    "date": "2025-03-07",
    "attention_score": 3.12,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04592v1",
    "title": "A Benchmark for Multi-Lingual Vision-Language Learning in Remote Sensing\n  Image Captioning",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04353v1",
    "title": "ObjMST: An Object-Focused Multimodal Style Transfer Framework",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04325v2",
    "title": "GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain\n  tumour Segmentation on mp-MRI",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04982v1",
    "title": "LVLM-Compress-Bench: Benchmarking the Broader Impact of Large\n  Vision-Language Model Compression",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04871v1",
    "title": "Toward Lightweight and Fast Decoders for Diffusion Models in Image and\n  Video Generation",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04919v1",
    "title": "FirePlace: Geometric Refinements of LLM Common Sense Reasoning for 3D\n  Object Placement",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04852v1",
    "title": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04205v1",
    "title": "Learning 3D Medical Image Models From Brain Functional Connectivity\n  Network Supervision For Mental Disorder Diagnosis",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04459v2",
    "title": "Question-Aware Gaussian Experts for Audio-Visual Question Answering",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04095v2",
    "title": "Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts",
    "date": "2025-03-06",
    "attention_score": 3.09,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03854v1",
    "title": "Vision-Language Models Struggle to Align Entities across Modalities",
    "date": "2025-03-05",
    "attention_score": 3.07,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03840v1",
    "title": "Decoupling the components of geometric understanding in Vision Language\n  Models",
    "date": "2025-03-05",
    "attention_score": 3.07,
    "attention_components": {
      "base_score": 1.6,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05064v1",
    "title": "Perceiving, Reasoning, Adapting: A Dual-Layer Framework for VLM-Guided\n  Precision Robotic Manipulation",
    "date": "2025-03-07",
    "attention_score": 2.73,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05149v1",
    "title": "Development and Enhancement of Text-to-Image Diffusion Models",
    "date": "2025-03-07",
    "attention_score": 2.73,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05132v1",
    "title": "R1-Zero's \"Aha Moment\" in Visual Reasoning on a 2B Non-SFT Model",
    "date": "2025-03-07",
    "attention_score": 2.73,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05305v1",
    "title": "Frequency Autoregressive Image Generation with Continuous Tokens",
    "date": "2025-03-07",
    "attention_score": 2.73,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04078v1",
    "title": "Spatial-Temporal Perception with Causal Inference for Naturalistic\n  Driving Action Recognition",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04918v1",
    "title": "Fine-Tuning Florence2 for Enhanced Object Detection in Un-constructed\n  Environments: Vision-Language Model Approach",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04121v1",
    "title": "Simple Self Organizing Map with Visual Transformer",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04457v1",
    "title": "TPC: Cross-Temporal Prediction Connection for Vision-Language Model\n  Hallucination Reduction",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04545v1",
    "title": "ViT-VS: On the Applicability of Pretrained Vision Transformer Features\n  for Generalizable Visual Servoing",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04639v1",
    "title": "Enhancing SAM with Efficient Prompting and Preference Optimization for\n  Semi-supervised Medical Image Segmentation",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04504v1",
    "title": "AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04144v1",
    "title": "DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person\n  Retrieval",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04058v1",
    "title": "EVE: Towards End-to-End Video Subtitle Extraction with Vision-Language\n  Models",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04506v1",
    "title": "Multi-modal Summarization in Model-Based Engineering: Automotive\n  Software Development Case Study",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04215v1",
    "title": "Energy-Guided Optimization for Personalized Image Editing with\n  Pretrained Text-to-Image Diffusion Models",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04724v1",
    "title": "LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04167v1",
    "title": "The Role of Visual Modality in Multimodal Mathematical Reasoning:\n  Challenges and Insights",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04130v1",
    "title": "Token-Efficient Long Video Understanding for Multimodal LLMs",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04006v1",
    "title": "DSV-LFS: Unifying LLM-Driven Semantic Cues with Visual Features for\n  Robust Few-Shot Segmentation",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04858v1",
    "title": "SHAPE : Self-Improved Visual Preference Alignment by Iteratively\n  Generating Holistic Winner",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04606v1",
    "title": "The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04417v1",
    "title": "From Idea to CAD: A Language Model-Driven Multi-Agent System for\n  Collaborative Design",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04201v1",
    "title": "Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative\n  Approach to Few-shot Multimodal Dialogue Intention Recognition",
    "date": "2025-03-06",
    "attention_score": 2.71,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03664v1",
    "title": "A Generative Approach to High Fidelity 3D Reconstruction from Text Data",
    "date": "2025-03-05",
    "attention_score": 2.68,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03613v1",
    "title": "CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards\n  Zero-shot Adversarial Robustness of CLIP",
    "date": "2025-03-05",
    "attention_score": 2.68,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03803v1",
    "title": "EgoLife: Towards Egocentric Life Assistant",
    "date": "2025-03-05",
    "attention_score": 2.68,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03935v1",
    "title": "GlucoLens: Explainable Postprandial Blood Glucose Prediction from Diet\n  and Physical Activity",
    "date": "2025-03-05",
    "attention_score": 2.68,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03734v1",
    "title": "OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature\n  Extraction",
    "date": "2025-03-05",
    "attention_score": 2.68,
    "attention_components": {
      "base_score": 1.4,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05689v1",
    "title": "GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories\n  Generation in End-to-End Autonomous Driving",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05228v1",
    "title": "RecipeGen: A Benchmark for Real-World Recipe Image Generation",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05255v1",
    "title": "CMMCoT: Enhancing Complex Multi-Image Comprehension via Multi-Modal\n  Chain-of-Thought and Memory Augmentation",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05236v1",
    "title": "Unified Reward Model for Multimodal Understanding and Generation",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05214v1",
    "title": "Gaussian Random Fields as an Abstract Representation of Patient Metadata\n  for Multimodal Medical Image Segmentation",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05534v1",
    "title": "S4M: Segment Anything with 4 Extreme Points",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05379v1",
    "title": "R1-Omni: Explainable Omni-Multimodal Emotion Recognition with\n  Reinforcing Learning",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05424v1",
    "title": "Towards Locally Explaining Prediction Behavior via Gradual Interventions\n  and Measuring Property Gradients",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05639v1",
    "title": "VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play\n  Context Control",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05298v1",
    "title": "Coreference as an indicator of context scope in multimodal narrative",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05595v1",
    "title": "Anti-Diffusion: Preventing Abuse of Modifications of Diffusion-Based\n  Models",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05684v1",
    "title": "Fairness-Aware Low-Rank Adaptation Under Demographic Privacy Constraints",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05335v1",
    "title": "New multimodal similarity measure for image registration via modeling\n  local functional dependence with linear combination of learned basis\n  functions",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05319v1",
    "title": "Robust Multimodal Learning for Ophthalmic Disease Grading via\n  Disentangled Representation",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05231v1",
    "title": "Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot\n  Learning and Human-Robot Interaction",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05186v1",
    "title": "Narrating the Video: Boosting Text-Video Retrieval via Comprehensive\n  Utilization of Frame-Level Captions",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05179v1",
    "title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  Cognitive-Inspired Sketching",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.05626v1",
    "title": "FMT:A Multimodal Pneumonia Detection Model Based on Stacking MOE\n  Framework",
    "date": "2025-03-07",
    "attention_score": 2.34,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9917808219178083,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04050v1",
    "title": "Underlying Semantic Diffusion for Effective and Efficient In-Context\n  Learning",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04199v1",
    "title": "MASTER: Multimodal Segmentation with Text Prompts",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04308v1",
    "title": "Shaken, Not Stirred: A Novel Dataset for Visual Understanding of Glasses\n  in Human-Robot Bartending Tasks",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04528v1",
    "title": "Federated Dynamic Modeling and Learning for Spatiotemporal Data\n  Forecasting",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04107v1",
    "title": "Fractional Correspondence Framework in Detection Transformer",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04490v1",
    "title": "Large Language Models in Bioinformatics: A Survey",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04971v1",
    "title": "Incentivizing Multi-Tenant Split Federated Learning for Foundation\n  Models at the Network Edge",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04135v1",
    "title": "Biological Sequence with Language Model Prompting: A Survey",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04900v1",
    "title": "Extracting Symbolic Sequences from Visual Representations via\n  Self-Supervised Learning",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04154v1",
    "title": "CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised\n  Monocular 3D Detection",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04170v1",
    "title": "Towards Intelligent Transportation with Pedestrians and Vehicles\n  In-the-Loop: A Surveillance Video-Assisted Federated Digital Twin Framework",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04406v1",
    "title": "Training-Free Graph Filtering via Multimodal Feature Refinement for\n  Extremely Fast Multimodal Recommendation",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04444v1",
    "title": "ToFu: Visual Tokens Reduction via Fusion for Multi-modal, Multi-patch,\n  Multi-image Task",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04252v1",
    "title": "RCRank: Multimodal Ranking of Root Causes of Slow Queries in Cloud\n  Database Systems",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04280v2",
    "title": "Towards Autonomous Reinforcement Learning for Real-World Robotic\n  Manipulation with Large Language Models",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04065v1",
    "title": "PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04250v1",
    "title": "An Egocentric Vision-Language Model based Portable Real-time Smart\n  Assistant",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04470v1",
    "title": "Gate-Shift-Pose: Enhancing Action Recognition in Sports with Skeleton\n  Information",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04110v1",
    "title": "InterChat: Enhancing Generative Visual Analytics using Multimodal\n  Interactions",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04641v1",
    "title": "Simulating the Real World: A Unified Survey of Multimodal Generative\n  Models",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04034v1",
    "title": "GaussianGraph: 3D Gaussian-based Scene Graph Generation for Open-world\n  Scene Understanding",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04478v1",
    "title": "Semantic Alignment of Unimodal Medical Text and Vision Representations",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04643v1",
    "title": "Adaptive Prototype Learning for Multimodal Cancer Survival Analysis",
    "date": "2025-03-06",
    "attention_score": 2.32,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.989041095890411,
      "source_weight": 1.0,
      "age_months": 0.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03663v2",
    "title": "LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03579v1",
    "title": "A Generative System for Robot-to-Human Handovers: from Intent Inference\n  to Spatial Configuration Imagery",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03689v1",
    "title": "DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with\n  Reward Guidance",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03947v1",
    "title": "COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for\n  Off-Road Semantic Segmentation",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03743v1",
    "title": "CHOP: Mobile Operating Assistant with Constrained High-frequency\n  Optimized Subtask Planning",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03848v1",
    "title": "Nexar Dashcam Collision Prediction Dataset and Challenge",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.04842v1",
    "title": "Replicating Human Social Perception in Generative AI: Evaluating the\n  Valence-Dominance Model",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "2503.03644v2",
    "title": "DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating\n  Semantic Understanding of Dongba Pictograms",
    "date": "2025-03-05",
    "attention_score": 2.3,
    "attention_components": {
      "base_score": 1.2,
      "recency_factor": 0.9863013698630136,
      "source_weight": 1.0,
      "age_months": 0.2,
      "citation_velocity": 0
    }
  },
  {
    "id": "paperswithcode_MME_Survey__A_Comprehensive_Survey_on_Evaluation_o",
    "title": "MME-Survey: A Comprehensive Survey on Evaluation of Multimodal LLMs",
    "date": "2024-03-11",
    "attention_score": 0.22,
    "attention_components": {
      "base_score": 1.8,
      "recency_factor": 0.1,
      "source_weight": 1.2,
      "age_months": 12.1,
      "citation_velocity": 0
    }
  },
  {
    "id": "2403.05916v2",
    "title": "GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual\n  Affective Computing",
    "date": "2024-03-09",
    "attention_score": 0.2,
    "attention_components": {
      "base_score": 2.0,
      "recency_factor": 0.1,
      "source_weight": 1.0,
      "age_months": 12.2,
      "citation_velocity": 0
    }
  }
]