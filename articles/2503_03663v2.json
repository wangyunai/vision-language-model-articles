{
  "id": "2503_03663v2",
  "title": "LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant",
  "url": "http://arxiv.org/abs/2503.03663v2",
  "pdf_url": "http://arxiv.org/pdf/2503.03663v2",
  "authors": [
    "Wei Li",
    "Bing Hu",
    "Rui Shao",
    "Leyang Shen",
    "Liqiang Nie"
  ],
  "date": "2025-03-05",
  "summary": "First-person video assistants are highly anticipated to enhance our daily\nlives through online video dialogue. However, existing online video assistants\noften sacrifice assistant efficacy for real-time efficiency by processing\nlow-frame-rate videos with coarse-grained visual features.To overcome the\ntrade-off between efficacy and efficiency, we propose \"Fast & Slow\nVideo-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving\nreal-time, proactive, temporally accurate, and contextually precise responses.\nLION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based\nResponse Determination evaluates frame-by-frame whether an immediate response\nis necessary. To enhance response determination accuracy and handle higher\nframe-rate inputs efficiently, we employ Token Aggregation Routing to\ndynamically fuse spatiotemporal features without increasing token numbers,\nwhile utilizing Token Dropping Routing to eliminate redundant features. 2)Slow\nPath: Multi-granularity Keyframe Augmentation optimizes keyframes during\nresponse generation. To provide comprehensive and detailed responses beyond\natomic actions constrained by training data, fine-grained spatial features and\nhuman-environment interaction features are extracted through multi-granular\npooling. These features are further integrated into a meticulously designed\nmultimodal Thinking Template to guide more precise response generation.\nComprehensive evaluations on online video tasks demonstrate that LION-FS\nachieves state-of-the-art efficacy and efficiency.",
  "source": "arXiv",
  "categories": [],
  "keywords": [
    "multimodal"
  ]
}