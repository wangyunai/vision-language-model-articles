{
  "id": "paperswithcode_X__2__VLM__All_In_One_Pre_trained_Model_For_Vision",
  "title": "X$^2$-VLM: All-In-One Pre-trained Model For Vision-Language Tasks",
  "url": "https://paperswithcode.com/paper/x-2-vlm-all-in-one-pre-trained-model-for",
  "authors": [],
  "date": "2024-03-17",
  "summary": "Vision language pre-training aims to learn alignments between vision and language from a large amount of data.",
  "source": "Papers With Code",
  "keywords": [
    "VLM",
    "vision-language"
  ],
  "code_url": null,
  "attention_score": 0.17,
  "attention_components": {
    "base_score": 1.4,
    "recency_factor": 0.1,
    "source_weight": 1.2,
    "age_months": 11.9,
    "citation_velocity": 0
  }
}