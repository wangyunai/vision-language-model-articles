{
  "id": "2503_03465v2",
  "title": "DTU-Net: A Multi-Scale Dilated Transformer Network for Nonlinear\n  Hyperspectral Unmixing",
  "url": "http://arxiv.org/abs/2503.03465v2",
  "pdf_url": "http://arxiv.org/pdf/2503.03465v2",
  "authors": [
    "ChenTong Wang",
    "Jincheng Gao",
    "Fei Zhu",
    "Abderrahim Halimi",
    "C\u00e9dric Richard"
  ],
  "date": "2024-03-05",
  "summary": "Transformers have shown significant success in hyperspectral unmixing (HU).\nHowever, challenges remain. While multi-scale and long-range spatial\ncorrelations are essential in unmixing tasks, current Transformer-based\nunmixing networks, built on Vision Transformer (ViT) or Swin-Transformer,\nstruggle to capture them effectively. Additionally, current Transformer-based\nunmixing networks rely on the linear mixing model, which lacks the flexibility\nto accommodate scenarios where nonlinear effects are significant. To address\nthese limitations, we propose a multi-scale Dilated Transformer-based unmixing\nnetwork for nonlinear HU (DTU-Net). The encoder employs two branches. The first\none performs multi-scale spatial feature extraction using Multi-Scale Dilated\nAttention (MSDA) in the Dilated Transformer, which varies dilation rates across\nattention heads to capture long-range and multi-scale spatial correlations. The\nsecond one performs spectral feature extraction utilizing 3D-CNNs with channel\nattention. The outputs from both branches are then fused to integrate\nmulti-scale spatial and spectral information, which is subsequently transformed\nto estimate the abundances. The decoder is designed to accommodate both linear\nand nonlinear mixing scenarios. Its interpretability is enhanced by explicitly\nmodeling the relationships between endmembers, abundances, and nonlinear\ncoefficients in accordance with the polynomial post-nonlinear mixing model\n(PPNMM). Experiments on synthetic and real datasets validate the effectiveness\nof the proposed DTU-Net compared to PPNMM-derived methods and several advanced\nunmixing networks.",
  "source": "arXiv",
  "categories": [],
  "keywords": [
    "vision transformer"
  ]
}