{
  "id": "2503.05298v1",
  "title": "Coreference as an indicator of context scope in multimodal narrative",
  "url": "http://arxiv.org/abs/2503.05298v1",
  "pdf_url": "http://arxiv.org/pdf/2503.05298v1",
  "authors": [
    "Nikolai Ilinykh",
    "Shalom Lappin",
    "Asad Sayeed",
    "Sharid Lo\u00e1iciga"
  ],
  "date": "2025-03-07",
  "summary": "We demonstrate that large multimodal language models differ substantially\nfrom humans in the distribution of coreferential expressions in a visual\nstorytelling task. We introduce a number of metrics to quantify the\ncharacteristics of coreferential patterns in both human- and machine-written\ntexts. Humans distribute coreferential expressions in a way that maintains\nconsistency across texts and images, interleaving references to different\nentities in a highly varied way. Machines are less able to track mixed\nreferences, despite achieving perceived improvements in generation quality.",
  "source": "arXiv",
  "categories": [],
  "keywords": [
    "multimodal"
  ],
  "attention_score": 2.34,
  "attention_components": {
    "base_score": 1.2,
    "recency_factor": 0.9917808219178083,
    "source_weight": 1.0,
    "age_months": 0.1,
    "citation_velocity": 0
  }
}