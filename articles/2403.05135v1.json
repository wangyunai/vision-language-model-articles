{
  "id": "2403.05135v1",
  "title": "ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment",
  "url": "http://arxiv.org/abs/2403.05135v1",
  "pdf_url": "http://arxiv.org/pdf/2403.05135v1",
  "authors": [
    "Xiwei Hu",
    "Rui Wang",
    "Yixiao Fang",
    "Bin Fu",
    "Pei Cheng",
    "Gang Yu"
  ],
  "date": "2024-03-08",
  "summary": "Diffusion models have demonstrated remarkable performance in the domain of\ntext-to-image generation. However, most widely used models still employ CLIP as\ntheir text encoder, which constrains their ability to comprehend dense prompts,\nencompassing multiple objects, detailed attributes, complex relationships,\nlong-text alignment, etc. In this paper, we introduce an Efficient Large\nLanguage Model Adapter, termed ELLA, which equips text-to-image diffusion\nmodels with powerful Large Language Models (LLM) to enhance text alignment\nwithout training of either U-Net or LLM. To seamlessly bridge two pre-trained\nmodels, we investigate a range of semantic alignment connector designs and\npropose a novel module, the Timestep-Aware Semantic Connector (TSC), which\ndynamically extracts timestep-dependent conditions from LLM. Our approach\nadapts semantic features at different stages of the denoising process,\nassisting diffusion models in interpreting lengthy and intricate prompts over\nsampling timesteps. Additionally, ELLA can be readily incorporated with\ncommunity models and tools to improve their prompt-following capabilities. To\nassess text-to-image models in dense prompt following, we introduce Dense\nPrompt Graph Benchmark (DPG-Bench), a challenging benchmark consisting of 1K\ndense prompts. Extensive experiments demonstrate the superiority of ELLA in\ndense prompt following compared to state-of-the-art methods, particularly in\nmultiple object compositions involving diverse attributes and relationships.",
  "source": "arXiv",
  "categories": [],
  "keywords": [
    "CLIP",
    "text-to-image",
    "image generation"
  ],
  "attention_score": 0.16,
  "attention_components": {
    "base_score": 1.6,
    "recency_factor": 0.1,
    "source_weight": 1.0,
    "age_months": 12.2,
    "citation_velocity": 0
  }
}