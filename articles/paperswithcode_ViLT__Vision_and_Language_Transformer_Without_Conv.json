{
  "id": "paperswithcode_ViLT__Vision_and_Language_Transformer_Without_Conv",
  "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision",
  "url": "https://paperswithcode.com/paper/vilt-vision-and-language-transformer-without",
  "authors": [],
  "date": "2024-03-27",
  "summary": "Vision-and-Language Pre-training (VLP) has improved performance on various joint vision-and-language downstream tasks.",
  "source": "Papers With Code",
  "keywords": [
    "vision-and-language"
  ],
  "code_url": null,
  "attention_score": 0.14,
  "attention_components": {
    "base_score": 1.2,
    "recency_factor": 0.1,
    "source_weight": 1.2,
    "age_months": 11.6,
    "citation_velocity": 0
  }
}