{
  "id": "2503_05534v1",
  "title": "S4M: Segment Anything with 4 Extreme Points",
  "url": "http://arxiv.org/abs/2503.05534v1",
  "pdf_url": "http://arxiv.org/pdf/2503.05534v1",
  "authors": [
    "Adrien Meyer",
    "Lorenzo Arboit",
    "Giuseppe Massimiani",
    "Francesco Brucchi",
    "Luca Emanuele Amodio",
    "Didier Mutter",
    "Nicolas Padoy"
  ],
  "date": "2025-03-07",
  "summary": "The Segment Anything Model (SAM) has revolutionized open-set interactive\nimage segmentation, inspiring numerous adapters for the medical domain.\nHowever, SAM primarily relies on sparse prompts such as point or bounding box,\nwhich may be suboptimal for fine-grained instance segmentation, particularly in\nendoscopic imagery, where precise localization is critical and existing prompts\nstruggle to capture object boundaries effectively. To address this, we\nintroduce S4M (Segment Anything with 4 Extreme Points), which augments SAM by\nleveraging extreme points -- the top-, bottom-, left-, and right-most points of\nan instance -- prompts. These points are intuitive to identify and provide a\nfaster, structured alternative to box prompts. However, a na\\\"ive use of\nextreme points degrades performance, due to SAM's inability to interpret their\nsemantic roles. To resolve this, we introduce dedicated learnable embeddings,\nenabling the model to distinguish extreme points from generic free-form points\nand better reason about their spatial relationships. We further propose an\nauxiliary training task through the Canvas module, which operates solely on\nprompts -- without vision input -- to predict a coarse instance mask. This\nencourages the model to internalize the relationship between extreme points and\nmask distributions, leading to more robust segmentation. S4M outperforms other\nSAM-based approaches on three endoscopic surgical datasets, demonstrating its\neffectiveness in complex scenarios. Finally, we validate our approach through a\nhuman annotation study on surgical endoscopic videos, confirming that extreme\npoints are faster to acquire than bounding boxes.",
  "source": "arXiv",
  "categories": [],
  "keywords": [
    "Segment Anything"
  ]
}